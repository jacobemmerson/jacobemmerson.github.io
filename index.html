---
layout: single
author_profile: true
---
<!--bundle exec jekyll serve-->
<html>
    <section>
        <h1>About</h1>
        I am a recent graduate from the <a target="_blank" href="https://www.sci.pitt.edu/">University of Pittsburgh</a> where I earned my B.Sc. in computer science. To further develop the equitable applications of language models, I leverage LLMs to identify domain-specific problems and propose solutions under Professor <a target="_blank" href="https://ryanzshi.github.io/">Ryan Shi</a>. Additionally, I help develop non-invasive prenatal screening techniques at <a target="_blank" href="https://signaturedx.com/">Signature Diagnostics</a> with Professor <a target="_blank" href="http://paulrcohen.github.io/">Paul Cohen</a>. Previously, I analyzed attention-level domain biases under Professor <a target="_blank" href="https://people.cs.pitt.edu/~kovashka/">Adriana Kovashka</a>.
        <br><br>
        
        In the Fall '24 academic term, I will be applying to PhD programs to contribute to our understanding of our increasingly complex models and how we can develop them to facilitate human-oriented goals.

    </section>
    <setion>
        <h2>Research Interests</h2>
        My research interests primarily fall under the fields of <b>Artificial Intelligence</b> and <b>Machine Learning</b>. With the rapid developments in both fields and a plethora of problems, I seemingly find new interests everyday. However, these topics have remained concrete over the past year:
        <ul>
            <li><b>Multimodal Machine Learning:</b> Language modeling with continuous data (audio, video), in-context learning with vision-language models, visual reasoning capabilities</li>
            <li><b>Commonsense and Reasoning:</b> Determining causality, decomposing complex problems, self-justification for generative models, hybrid neuro-symbolic architectures</li>
            <li><b>Domain Adaptability of Large Models:</b> Are our models equitable? How can we combat data-driven biases? Can we leverage non-parallel out-of-domain data to mitigate culture-specific biases?</li>
            <li><b>A.I. for Social Good:</b> personalized education, resource allocation, detection of fraudulent content, in-the-loop automated tasks</li>
        </ul>
    </setion>
    <section>
        <h2>Education</h2>
            <div class="notice">
                <strong>B.Sc. Computer Science</strong> (Summa Cum Laude)
                <p>University of Pittsburgh, 3.91/4.00</p>
            </div>
            <div class="notice">
                <strong>Minor in Applied Statistics</strong> (Summa Cum Laude)
                <p>University of Pittsburgh, 4.00/4.00</p>
            </div>
    </section>
    <section>
        <h2>Tidbits</h2>
        <ul>
            <li>While most people refer to me as Jacob, my friends like to call me Tae (you can too!). Unfortunately, I am cursed with the <a target="_blank" href="https://www.ssa.gov/oact/babynames/decades/names2000s.html">most popular name</a> during the 2000s.</li>
            <li>I worked in the coffee industry for 3 years before starting a career in machine learning research; if you're in Pittsburgh, I recommend <a target="_blank" href = "https://commonplacecoffee.com/">Commonplace Coffee</a>!</li>
            <li>During the pandemic, I made a very last minute decision to pivot and pursue a computer science degree over (cognitive) neuroscience. Why? I didn't want a PhD... but... well...</li>
        </ul>
    </section>
</html>